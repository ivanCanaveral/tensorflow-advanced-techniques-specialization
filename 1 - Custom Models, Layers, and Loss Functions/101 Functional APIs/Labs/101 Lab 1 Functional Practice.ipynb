{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ungraded Lab: Practice with the Keras Functional API\n",
    "\n",
    "This lab will demonstrate how to build models with the Functional syntax. You'll build one using the Sequential API and see how you can do the same with the Functional API. Both will arrive at the same architecture and you can train and evaluate it as usual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential API\n",
    "\n",
    "Here is how we use the `Sequential()` class to build a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "04Y-C9RYUTes"
   },
   "outputs": [],
   "source": [
    "def build_model_with_sequential():\n",
    "    \"\"\"\n",
    "    instantiate a Sequential class and linearly stack the layers\n",
    "    of your model\n",
    "    \"\"\"\n",
    "    seq_model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "        ]\n",
    "    )\n",
    "    return seq_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional API\n",
    "\n",
    "And here is how you build the same model above with the functional syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "tf.keras.layers.Dense(\n",
    "    units,\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    **kwargs\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_with_functional_api():\n",
    "    input_layer = tf.keras.layers.Input(shape=(28, 28), name='input')\n",
    "    flattened = tf.keras.layers.Flatten()(input_layer)\n",
    "    first_layer = tf.keras.layers.Dense(128, activation=tf.nn.relu, name='first_layer')(flattened)\n",
    "    output_layer = tf.keras.layers.Dense(10, activation=tf.nn.softmax, name='output_layer')(first_layer)\n",
    "    # Once the dependency graph is ready, let's define the model\n",
    "    func_model = tf.keras.Model(input_layer, output_layer, name='my_model')\n",
    "    return func_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model and visualize the model graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose how to build your model below. Just uncomment which function you'd like to use. You'll notice that the plot will look the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model_with_functional_api()\n",
    "#model = build_model_with_sequential()\n",
    "\n",
    "# Plot model graph\n",
    "plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layer('first_layer').weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(\n",
    "    model.get_layer('first_layer').weights[0].numpy().flatten(),\n",
    "    50,\n",
    "    facecolor='b',\n",
    "    alpha=0.75\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.layers[2].weights[0].shape, '\\n', model.layers[3].weights[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Regardless if you built it with the Sequential or Functional API, you'll follow the same steps when training and evaluating your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare fashion mnist dataset\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[0, 1, 0], [0, 0, 1]]\n",
    "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
    "loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "assert loss.shape == (2,)\n",
    "loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[0, 1, 0], [0, 0, 1]]\n",
    "y_pred = [[0.05, 0.95, 0], [0.1, 0.1, 0.8]]\n",
    "loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "assert loss.shape == (2,)\n",
    "loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]\n",
    "y_pred = [[0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]\n",
    "loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "assert loss.shape == (2,)\n",
    "loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [1, 2] # -> [[0, 1, 0], [0, 0, 1]]\n",
    "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]] # -> Model's outputs is supposed to be this way\n",
    "loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "assert loss.shape == (2,)\n",
    "loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = one_hot(y_true) = [[0, 1, 0], [0, 0, 1]]\n",
    "# logits = log(y_pred)\n",
    "# softmax = exp(logits) / sum(exp(logits), axis=-1)\n",
    "# softmax = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]\n",
    "# xent = -sum(y * log(softmax), 1)\n",
    "# log(softmax) = [[-2.9957, -0.0513, -16.1181],\n",
    "#                [-2.3026, -0.2231, -2.3026]]\n",
    "# y_true * log(softmax) = [[0, -0.0513, 0], [0, 0, -2.3026]]\n",
    "# xent = [0.0513, 2.3026]\n",
    "# Reduced xent = (0.0513 + 2.3026) / 2\n",
    "m = tf.keras.metrics.SparseCategoricalCrossentropy()\n",
    "m.update_state([1, 2],\n",
    "               [[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.reset_state()\n",
    "m.update_state([1, 2],\n",
    "               [[0.05, 0.95, 0], [0.1, 0.8, 0.1]],\n",
    "               sample_weight=tf.constant([0.3, 0.7]))\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    loss=tf.keras.metrics.sparse_categorical_crossentropy,\n",
    "    metrics=[\n",
    "        tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "        tf.keras.metrics.SparseCategoricalCrossentropy()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    training_images,\n",
    "    training_labels,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "FunctionalCoLab1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
